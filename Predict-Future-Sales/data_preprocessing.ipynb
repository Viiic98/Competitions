{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['items.csv', 'item_categories.csv', 'sales_train.csv', 'sample_submission.csv', 'shops.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import gc\n",
    "import itertools\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # Plot library\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from time import sleep\n",
    "#from pathlib2 import Path\n",
    "from tqdm import notebook\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/competitive-data-science-predict-future-sales\" directory.\n",
    "import os\n",
    "print(os.listdir(\"data\"))\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('data/items.csv')\n",
    "shops = pd.read_csv('data/shops.csv')\n",
    "sales_train = pd.read_csv('data/sales_train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "item_categories = pd.read_csv('data/item_categories.csv')\n",
    "groupby_cols = ['date_block_num', 'shop_id', 'item_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train = sales_train[sales_train.item_price < 100000]\n",
    "sales_train = sales_train[sales_train.item_cnt_day < 1001]\n",
    "\n",
    "median = sales_train[(sales_train.shop_id == 32) & (sales_train.item_id == 2973) & (sales_train.date_block_num == 4) & (\n",
    "            sales_train.item_price > 0)].item_price.median()\n",
    "sales_train.loc[sales_train.item_price < 0, 'item_price'] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train.loc[sales_train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "sales_train.loc[sales_train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "sales_train.loc[sales_train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11\n",
    "\n",
    "test['date_block_num'] = 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = items[['item_id', 'item_category_id']].drop_duplicates()\n",
    "category.set_index(['item_id'], inplace=True)\n",
    "category = category.item_category_id\n",
    "sales_train['category'] = sales_train.item_id.map(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_categories['meta_category'] = item_categories.item_category_name.apply(lambda x: x.split(' ')[0])\n",
    "item_categories['meta_category'] = pd.Categorical(item_categories.meta_category).codes\n",
    "item_categories.set_index(['item_category_id'], inplace=True)\n",
    "meta_category = item_categories.meta_category\n",
    "sales_train['meta_category'] = sales_train.category.map(meta_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops['city'] = shops.shop_name.apply(lambda x: str.replace(x, '!', '')).apply(lambda x: x.split(' ')[0])\n",
    "shops['city'] = pd.Categorical(shops['city']).codes\n",
    "city = shops.city\n",
    "sales_train['city'] = sales_train.shop_id.map(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = pd.concat([sales_train.date_block_num, sales_train.date.apply(lambda x: int(x.split('.')[2]))], axis=1).drop_duplicates()\n",
    "year.set_index(['date_block_num'], inplace=True)\n",
    "year = year.date.append(pd.Series([2015], index=[34]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = pd.concat([sales_train.date_block_num, sales_train.date.apply(lambda x: int(x.split('.')[1]))], axis=1).drop_duplicates()\n",
    "month.set_index(['date_block_num'], inplace=True)\n",
    "month = month.date.append(pd.Series([11], index=[34]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shops_items = []\n",
    "\n",
    "for block_num in sales_train['date_block_num'].unique():\n",
    "    unique_shops = sales_train[sales_train['date_block_num'] == block_num]['shop_id'].unique()\n",
    "    unique_items = sales_train[sales_train['date_block_num'] == block_num]['item_id'].unique()\n",
    "    all_shops_items.append(np.array(list(itertools.product([block_num], unique_shops, unique_items)), dtype='int32'))\n",
    "\n",
    "df = pd.DataFrame(np.vstack(all_shops_items), columns=groupby_cols, dtype='int32')\n",
    "df = df.append(test, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df.ID.fillna(-1).astype('int32')\n",
    "df['year'] = df.date_block_num.map(year)\n",
    "df['month'] = df.date_block_num.map(month)\n",
    "df['category'] = df.item_id.map(category)\n",
    "df['meta_category'] = df.category.map(meta_category)\n",
    "df['city'] = df.shop_id.map(city)\n",
    "sales_train['category'] = sales_train.item_id.map(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gb = sales_train.groupby(by=groupby_cols, as_index=False).agg({'item_cnt_day': ['sum']})\n",
    "gb.columns = [val[0] if val[-1] == '' else '_'.join(val) for val in gb.columns.values]\n",
    "gb.rename(columns={'item_cnt_day_sum': 'target'}, inplace=True)\n",
    "df = pd.merge(df, gb, how='left', on=groupby_cols)\n",
    "\n",
    "gb = sales_train.groupby(by=['date_block_num', 'item_id'], as_index=False).agg({'item_cnt_day': ['sum']})\n",
    "gb.columns = [val[0] if val[-1] == '' else '_'.join(val) for val in gb.columns.values]\n",
    "gb.rename(columns={'item_cnt_day_sum': 'target_item'}, inplace=True)\n",
    "df = pd.merge(df, gb, how='left', on=['date_block_num', 'item_id'])\n",
    "\n",
    "gb = sales_train.groupby(by=['date_block_num', 'shop_id'], as_index=False).agg({'item_cnt_day': ['sum']})\n",
    "gb.columns = [val[0] if val[-1] == '' else '_'.join(val) for val in gb.columns.values]\n",
    "gb.rename(columns={'item_cnt_day_sum': 'target_shop'}, inplace=True)\n",
    "df = pd.merge(df, gb, how='left', on=['date_block_num', 'shop_id'])\n",
    "\n",
    "gb = sales_train.groupby(by=['date_block_num', 'category'], as_index=False).agg({'item_cnt_day': ['sum']})\n",
    "gb.columns = [val[0] if val[-1] == '' else '_'.join(val) for val in gb.columns.values]\n",
    "gb.rename(columns={'item_cnt_day_sum': 'target_category'}, inplace=True)\n",
    "df = pd.merge(df, gb, how='left', on=['date_block_num', 'category'])\n",
    "\n",
    "gb = sales_train.groupby(by=['date_block_num', 'item_id'], as_index=False).agg({'item_price': ['mean', 'max']})\n",
    "gb.columns = [val[0] if val[-1] == '' else '_'.join(val) for val in gb.columns.values]\n",
    "gb.rename(columns={'item_price_mean': 'target_price_mean', 'item_price_max': 'target_price_max'}, inplace=True)\n",
    "df = pd.merge(df, gb, how='left', on=['date_block_num', 'item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_price_mean'] = np.minimum(df['target_price_mean'], df['target_price_mean'].quantile(0.99))\n",
    "df['target_price_max'] = np.minimum(df['target_price_max'], df['target_price_max'].quantile(0.99))\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "df['target'] = df['target'].clip(0, 20)\n",
    "df['target_zero'] = (df['target'] > 0).astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac35a26d3af475b91e752e0ecf36eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da077a87c3b44fdb5eb679c7523bf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71904f8c6d754658843817e91ee3836c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for enc_cols in [['shop_id', 'category'], ['shop_id', 'item_id'], ['shop_id'], ['item_id']]:\n",
    "\n",
    "    col = '_'.join(['enc', *enc_cols])\n",
    "    col2 = '_'.join(['enc_max', *enc_cols])\n",
    "    df[col] = np.nan\n",
    "    df[col2] = np.nan\n",
    "\n",
    "    for d in notebook.tqdm(df.date_block_num.unique()):\n",
    "        f1 = df.date_block_num < d\n",
    "        f2 = df.date_block_num == d\n",
    "\n",
    "        gb = df.loc[f1].groupby(enc_cols)[['target']].mean().reset_index()\n",
    "        enc = df.loc[f2][enc_cols].merge(gb, on=enc_cols, how='left')[['target']].copy()\n",
    "        enc.set_index(df.loc[f2].index, inplace=True)\n",
    "        df.loc[f2, col] = enc['target']\n",
    "\n",
    "        gb = df.loc[f1].groupby(enc_cols)[['target']].max().reset_index()\n",
    "        enc = df.loc[f2][enc_cols].merge(gb, on=enc_cols, how='left')[['target']].copy()\n",
    "        enc.set_index(df.loc[f2].index, inplace=True)\n",
    "        df.loc[f2, col2] = enc['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    float32_cols = [c for c in df if df[c].dtype == 'float64']\n",
    "    int32_cols = [c for c in df if df[c].dtype in ['int64', 'int16', 'int8']]\n",
    "\n",
    "    df[float32_cols] = df[float32_cols].astype(np.float32)\n",
    "    df[int32_cols] = df[int32_cols].astype(np.int32)\n",
    "\n",
    "    return df\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "df = downcast_dtypes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "shift_range = [1, 2, 3, 4, 5, 12]\n",
    "\n",
    "shifted_columns = [c for c in df if 'target' in c]\n",
    "\n",
    "for shift in notebook.tqdm(shift_range):\n",
    "    shifted_data = df[groupby_cols + shifted_columns].copy()\n",
    "    shifted_data['date_block_num'] = shifted_data['date_block_num'] + shift\n",
    "\n",
    "    foo = lambda x: '{}_lag_{}'.format(x, shift) if x in shifted_columns else x\n",
    "    shifted_data = shifted_data.rename(columns=foo)\n",
    "\n",
    "    df = pd.merge(df, shifted_data, how='left', on=groupby_cols).fillna(0)\n",
    "    df = downcast_dtypes(df)\n",
    "\n",
    "    del shifted_data\n",
    "    gc.collect()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_trend_1_2'] = df['target_lag_1'] - df['target_lag_2']\n",
    "df['target_predict_1_2'] = df['target_lag_1'] * 2 - df['target_lag_2']\n",
    "\n",
    "df['target_trend_3_4'] = df['target_lag_1'] + df['target_lag_2'] - df['target_lag_3'] - df['target_lag_4']\n",
    "df['target_predict_3_4'] = (df['target_lag_1'] + df['target_lag_2']) * 2 - df['target_lag_3'] - df['target_lag_4']\n",
    "\n",
    "df['target_item_trend_1_2'] = df['target_item_lag_1'] - df['target_item_lag_2']\n",
    "df['target_item_trend_3_4'] = df['target_item_lag_1'] + df['target_item_lag_2'] - df['target_item_lag_3'] - df['target_item_lag_4']\n",
    "df['target_shop_trend_1_2'] = df['target_shop_lag_1'] - df['target_shop_lag_2']\n",
    "df['target_shop_trend_3_4'] = df['target_shop_lag_1'] + df['target_shop_lag_2'] - df['target_shop_lag_3'] - df['target_shop_lag_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = downcast_dtypes(df)\n",
    "df.to_pickle('data-pre/df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
